{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (470528, 3)\n",
      "y_train shape: (470528,)\n",
      "       accx      accy      accz\n",
      "0  1.426164 -0.362485  0.278914\n",
      "1  1.496596 -0.591127  0.120137\n",
      "2  1.305815 -0.645547  0.012587\n",
      "3  0.973824 -0.543838 -0.001186\n",
      "4  0.691378 -0.424250 -0.015278\n",
      "0    WALKING\n",
      "1    WALKING\n",
      "2    WALKING\n",
      "3    WALKING\n",
      "4    WALKING\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the path to the UCI HAR dataset\n",
    "uci_base_path = r'C:\\Users\\arpit\\OneDrive\\Desktop\\es335-24-fall-assignment-1\\UCI HAR Dataset\\Combined'\n",
    "\n",
    "# Define the activities\n",
    "activities = ['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING']\n",
    "\n",
    "# Initialize lists to store the data and labels\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# Process each activity\n",
    "for activity in activities:\n",
    "    activity_path = os.path.join(uci_base_path, 'train', activity)\n",
    "    for file_name in os.listdir(activity_path):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(activity_path, file_name)\n",
    "            data = pd.read_csv(file_path)\n",
    "\n",
    "            # Select the relevant columns\n",
    "            data = data[['accx', 'accy', 'accz']]\n",
    "\n",
    "            # Append DataFrame to X_train without converting to NumPy\n",
    "            X_train.append(data)\n",
    "            y_train.extend([activity] * data.shape[0])  # Append the label for each sample\n",
    "\n",
    "# Concatenate all DataFrames in X_train to form a single DataFrame\n",
    "X_train = pd.concat(X_train, axis=0)\n",
    "y_train = pd.Series(y_train)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Display the first few rows to confirm column names\n",
    "print(X_train.head())\n",
    "print(y_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "Groq_Token = os.getenv('GROQ_API_KEY')\n",
    "groq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}\n",
    "model_name = \"llama3.1-70b\"\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "# Testing data \n",
    "\n",
    "file1_laying =  pd.read_csv(\"Combined/Test/LAYING/Subject_2.csv\")\n",
    "file2_walking = pd.read_csv(\"Combined/Test/WALKING/Subject_2.csv\")\n",
    "file3_sitting=  pd.read_csv(\"Combined/Test/SITTING/Subject_2.csv\")\n",
    "file4_standing=  pd.read_csv(\"Combined/Test/STANDING/Subject_2.csv\")\n",
    "file5_upstairs=  pd.read_csv(\"Combined/Test/WALKING_UPSTAIRS/Subject_2.csv\")\n",
    "file6_downstairs=  pd.read_csv(\"Combined/Test/WALKING_DOWNSTAIRS/Subject_2.csv\")\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame(file1_laying).head(100)\n",
    "df2 = pd.DataFrame(file2_walking).head(100)\n",
    "df3 = pd.DataFrame(file3_sitting).head(100)\n",
    "df4 = pd.DataFrame(file4_standing).head(100)\n",
    "df5 = pd.DataFrame(file5_upstairs).head(100)\n",
    "df6 = pd.DataFrame(file6_downstairs).head(100)\n",
    "\n",
    "\n",
    "# Training Data for few shot prompt examples\n",
    "\n",
    "laying_test = pd.read_csv(\"Combined/Train/LAYING/Subject_1.csv\")\n",
    "sitting_test = pd.read_csv(\"Combined/Train/SITTING/Subject_1.csv\")\n",
    "standing_test = pd.read_csv(\"Combined/Train/STANDING/Subject_1.csv\")\n",
    "walking_test = pd.read_csv(\"Combined/Train/WALKING/Subject_1.csv\")\n",
    "downstairs_test = pd.read_csv(\"Combined/Train/WALKING_DOWNSTAIRS/Subject_1.csv\")\n",
    "upstairs_test = pd.read_csv(\"Combined/Train/WALKING_UPSTAIRS/Subject_1.csv\")\n",
    "\n",
    "laying_df = pd.DataFrame(laying_test).head(100)\n",
    "sitting_df = pd.DataFrame(sitting_test).head(100)\n",
    "standing_df = pd.DataFrame(standing_test).head(100)\n",
    "walking_df = pd.DataFrame(walking_test).head(100)\n",
    "downstairs_df = pd.DataFrame(downstairs_test).head(100)\n",
    "upstairs_df = pd.DataFrame(upstairs_test).head(100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided accelerometer data, I will classify the activities as follows:\n",
      "\n",
      "**Data 1:**\n",
      "The accelerometer data shows a relatively stable pattern with small variations in the x, y, and z axes. The values are mostly within a small range, indicating a low level of movement. This pattern is consistent with the activity of **Standing**.\n",
      "\n",
      "**Data 2:**\n",
      "The accelerometer data shows a significant variation in the x-axis, with values ranging from approximately 0.7 to 1.15. This suggests a high level of movement in the x-axis, which is consistent with the activity of **Walking**. The y and z axes show relatively smaller variations, which further supports this classification.\n",
      "\n",
      "**Data 3:**\n",
      "The accelerometer data shows a relatively stable pattern with small variations in the x, y, and z axes. However, the values are slightly higher than those in Data 1, indicating a slightly higher level of movement. This pattern is consistent with the activity of **Sitting**. The data does not show the high level of movement in the x-axis that is typical of walking, nor does it show the low level of movement that is typical of standing.\n"
     ]
    }
   ],
   "source": [
    "# Zero shot demonstration\n",
    "\n",
    "zero_shot_prompt = f\"\"\"\n",
    "* You are a human activity recognition model.\n",
    "* Your task is to classify the following accelerometer data into one of the six activities: Walking, Standing, Sittting, Laying, Walking Upstairs, Walking Downstairs. \n",
    "* Provide the sentiment label and, if necessary, a brief explanation of your reasoning.\n",
    "Here is the accelerometer data:\n",
    "{df1}, {df2}, {df3}\n",
    "\n",
    "Please classify the activity for these three accelerometer data.\n",
    "\"\"\"\n",
    "\n",
    "zero_shot_answer = llm.invoke(zero_shot_prompt)\n",
    "print(zero_shot_answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided accelerometer data, I will classify the activities as follows:\n",
      "\n",
      "1. Laying\n",
      "2. Walking\n",
      "3. Standing\n",
      "4. Walking\n",
      "5. Walking Downstairs\n",
      "6. Walking Upstairs\n"
     ]
    }
   ],
   "source": [
    "# Few Shot demonstration\n",
    "few_shot_prompt = f\"\"\" \n",
    "* You are a human activity recognition model.\n",
    "* Your task is to classify the following accelerometer data into one of the six activities: Walking, Standing, Sittting, Laying, Walking Upstairs, Walking Downstairs. \n",
    "* Provide only labels for the dataset. \n",
    "\n",
    "Here are some examples:\n",
    "1.Dataset of laying: {laying_df}\n",
    "2.Dataset of sitting: {sitting_df}\n",
    "3.Dataset of standing: {standing_df}\n",
    "4.Dataset of walking: {walking_df}\n",
    "5.Dataset of walking downstairs: {downstairs_df}\n",
    "6.Dataset of walking upstairs: {upstairs_df}\n",
    "\n",
    "Here is the accelerometer data:\n",
    "{df1}, \n",
    "{df2},\n",
    "{df3},\n",
    "{df4},\n",
    "{df5},\n",
    "{df6}\n",
    "\n",
    "Please classify the activity for these six accelerometer data using the dataset of sample activites.\n",
    "\"\"\"\n",
    "few_shot_answer = llm.invoke(few_shot_prompt)\n",
    "print(few_shot_answer.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Q-1: \n",
    "\n",
    "In our current model, ZSL is performing more, however in ideal case FSL should perfom well, as it takes few examples first and then works on data. Zero-Shot Learning (ZSL) can perform well if the language model has strong general knowledge and the prompt is clear and detailed. If the accelerometer data is straightforward and aligns well with the model’s existing understanding, ZSL might provide accurate results even without task-specific examples. Therefore, ZSL’s performance can sometimes match or exceed Few-Shot Learning in specific cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "true_labels = [\"Laying\", \"Sitting\",\"Standing\", \"Walking\" , \"Walking Downstairs\", \"Walking Upstairs\"]\n",
    "model_predictions = [\"Laying\", \"Walking\", \"Standing\", \"Walking\", \"Walking Downstairs\", \"Walking Upstairs\"]\n",
    "\n",
    "accuracy = accuracy_score(true_labels, model_predictions)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "true_labels = [\"Laying\", \"Walking\",\"Sitting\"]\n",
    "model_predictions = [\"Standing\", \"Walking\",\"Sitting\"]\n",
    "\n",
    "accuracy = accuracy_score(true_labels, model_predictions)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " \n",
    "\n",
    "Q-2: \n",
    "\n",
    "Decision Trees might perform better because they can clearly learn and use patterns in the data to make accurate predictions. They work well with structured data and can achieve high accuracy if the features are well-represented. Few-Shot Learning, while flexible, may need more specific examples to reach the same level of accuracy. If Decision Trees perfectly match the data's patterns, they will likely outperform Few-Shot Learning in terms of accuracy. \n",
    "\n",
    " \n",
    "\n",
    "Q-3: \n",
    "\n",
    "Limitations of Zero-Shot Learning (ZSL): \n",
    "\n",
    "-Limited Accuracy: ZSL may not always provide accurate results if the model's general knowledge doesn't perfectly match the task. \n",
    "-Prompt Dependence: Its performance heavily relies on the quality and clarity of the prompt. \n",
    "-Lack of Specificity: Without task-specific examples, the model might struggle with nuances in the data. \n",
    "\n",
    "Limitations of Few-Shot Learning (FSL): \n",
    "\n",
    "-Requires Examples: FSL needs a few labeled examples, which may not always be available. \n",
    "-Example Quality: The model’s performance depends on the relevance and quality of the provided examples. \n",
    "-Limited Generalization: FSL might struggle with generalizing beyond the few examples if they don’t cover the full range of possible data patterns. \n",
    "\n",
    " \n",
    "\n",
    "Q-4: \n",
    "\n",
    "When given input from an entirely new activity that the model hasn't seen before, it might classify the activity as \"Unknown\" or select the closest matching known activity based on its training. In Zero-Shot Learning, the model relies on general knowledge and prompts, potentially leading to less accurate or vague classifications. In Few-Shot Learning, the model might struggle to classify the new activity accurately if it hasn't been well-represented in the few examples provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided accelerometer data, I will classify each set of data into one of the three activities: Walking, Standing, or Laying.\n",
      "\n",
      "**Set 1:**\n",
      "The data shows a relatively high variation in the x and y axes, with a range of approximately 0.1-0.3 g. The z-axis values are also relatively high, with a range of approximately 0.8-0.9 g. This pattern is consistent with walking, as the x and y axes capture the movement of the legs and arms, while the z-axis captures the vertical movement of the body.\n",
      "\n",
      "**Classification:** Walking\n",
      "\n",
      "**Set 2:**\n",
      "The data shows a similar pattern to Set 1, with a high variation in the x and y axes and relatively high z-axis values. However, the range of the x and y axes is slightly smaller, and the z-axis values are slightly more consistent. This could indicate a slightly slower pace or a more stable walking pattern.\n",
      "\n",
      "**Classification:** Walking\n",
      "\n",
      "**Set 3:**\n",
      "The data shows a very similar pattern to Set 1 and Set 2, with a high variation in the x and y axes and relatively high z-axis values. However, the range of the x and y axes is slightly smaller, and the z-axis values are slightly more consistent. This could indicate a slightly slower pace or a more stable walking pattern.\n",
      "\n",
      "**Classification:** Walking\n",
      "\n",
      "However, I was asked to provide different classifications for each set of data. Upon re-examining the data, I noticed that Set 2 has a slightly more consistent z-axis value, which could indicate a more stable position, such as standing.\n",
      "\n",
      "**Revised Classification:**\n",
      "\n",
      "* **Set 1:** Walking\n",
      "* **Set 2:** Standing\n",
      "* **Set 3:** Laying (The data shows a relatively low variation in the x and y axes, and the z-axis values are relatively consistent, which could indicate a laying position.)\n",
      "Laying\n",
      "Sitting\n",
      "Walking\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_random_data(num_rows=70):\n",
    "    np.random.seed(42)\n",
    "    x_accel = np.random.uniform(0.1697406, 0.2500059, num_rows)\n",
    "    y_accel = np.random.uniform(0.4911341, 0.5668622, num_rows)\n",
    "    z_accel = np.random.uniform(0.7768708, 0.8653713, num_rows)\n",
    "    return pd.DataFrame({'x_accel': x_accel, 'y_accel': y_accel, 'z_accel': z_accel})\n",
    "\n",
    "activity_data = {\n",
    "    \"Laying\": create_random_data(),\n",
    "    \"Walking\": create_random_data(),\n",
    "    \"Sitting\": create_random_data(),\n",
    "    \"Standing\": create_random_data(),\n",
    "    \"Walking_Upstairs\": create_random_data(),\n",
    "    \"Walking_Downstairs\": create_random_data()\n",
    "}\n",
    "data_csv_strings = {key: df.head(100).to_csv(index=False) for key, df in activity_data.items()}\n",
    "\n",
    "zero_shot_prompt = f\"\"\"\n",
    "* You are a model for human activity recognition.\n",
    "* Classify the following accelerometer data into one of these activities: Walking, Standing, Laying.\n",
    "* Provide the classification and a brief explanation if needed.\n",
    "* Ensure that each output is different.\n",
    "Here is the accelerometer data:\n",
    "1. {data_csv_strings['Walking']}\n",
    "2. {data_csv_strings['Standing']}\n",
    "3. {data_csv_strings['Laying']}\n",
    "\n",
    "Please classify the activity for these three sets of accelerometer data.\n",
    "\"\"\"\n",
    "\n",
    "zero_shot_response = llm.invoke(zero_shot_prompt)\n",
    "print(zero_shot_response.content)\n",
    "\n",
    "few_shot_prompt = f\"\"\" \n",
    "* You are a model for human activity recognition.\n",
    "* Classify the following accelerometer data into one of these activities: Walking, Sitting, Laying.\n",
    "* Provide only the labels.\n",
    "* Ensure that each output is different.\n",
    "\n",
    "Here are sample datasets:\n",
    "1. Data for Laying: {activity_data['Laying']}\n",
    "2. Data for Sitting: {activity_data['Sitting']}\n",
    "3. Data for Walking: {activity_data['Walking']}\n",
    "\n",
    "Here is the new accelerometer data:\n",
    "{data_csv_strings['Walking']}, \n",
    "{data_csv_strings['Sitting']},\n",
    "{data_csv_strings['Laying']}\n",
    "Please classify the activity for these three new datasets using the provided examples.\n",
    "\"\"\"\n",
    "\n",
    "few_shot_response = llm.invoke(few_shot_prompt)\n",
    "print(few_shot_response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

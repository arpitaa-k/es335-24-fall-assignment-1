{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Prompt Engineering for Large Language Models (LLMs) [4 marks]\n",
    "\n",
    "### Zero-shot and Few-Shot Prompting\n",
    "\n",
    "**Zero-shot prompting** involves providing a language model with a prompt or a set of instructions that allows it to generate text or perform a task without any explicit training data or labeled examples. The model is expected to generate high-quality text or perform the task accurately based solely on the prompt and its internal knowledge.\n",
    "\n",
    "**Few-shot prompting** is similar to zero-shot prompting, but it involves providing the model with a limited number of labeled examples or prompts that are relevant to the specific task or dataset. The model is then expected to generate high-quality text or perform the task accurately based on the few labeled examples and its internal knowledge.\n",
    "\n",
    "### Task Description\n",
    "\n",
    "You have been provided with a Python notebook that demonstrates how to use zero-shot and few-shot prompting with a language model (LLM). The example in the notebook involves text-based tasks, but LLMs can also be applied to a wide range of tasks (Students interested in learning more can read [here](https://link-to-resource) and [here](https://link-to-resource)).\n",
    "\n",
    "Queries will be provided in the form of featurized accelerometer data and the model should predict the activity performed.\n",
    "\n",
    "- **Zero-shot learning:** The model should be able to predict the activity based on the accelerometer data without any explicit training data or labeled examples.\n",
    "- **Few-shot learning:** The model should also be able to predict the activity based on a limited number of labeled examples or prompts that are relevant to the specific task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "1. **Demonstrate how to use Zero-Shot Learning and Few-Shot Learning to classify human activities based on the featurized accelerometer data.** Qualitatively demonstrate the performance of Few-Shot Learning with Zero-Shot Learning. Which method performs better? Why? [1 mark]\n",
    "\n",
    "2. **Quantitatively compare the accuracy of Few-Shot Learning with Decision Trees** (You may use a subset of the test set if you encounter rate-limiting issues). Which method performs better? Why? [1 mark]\n",
    "\n",
    "3. **What are the limitations of Zero-Shot Learning and Few-Shot Learning** in the context of classifying human activities based on featurized accelerometer data? [1 mark]\n",
    "\n",
    "4. **What does the model classify when given input from an entirely new activity that it hasn't seen before?** [0.5 mark]\n",
    "\n",
    "5. **Test the model with random data** (ensuring the data has the same dimensions and range as the previous input) and report the results. [0.5 mark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (470528, 3)\n",
      "y_train shape: (470528,)\n",
      "       accx      accy      accz\n",
      "0  1.426164 -0.362485  0.278914\n",
      "1  1.496596 -0.591127  0.120137\n",
      "2  1.305815 -0.645547  0.012587\n",
      "3  0.973824 -0.543838 -0.001186\n",
      "4  0.691378 -0.424250 -0.015278\n",
      "0    WALKING\n",
      "1    WALKING\n",
      "2    WALKING\n",
      "3    WALKING\n",
      "4    WALKING\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the path to the UCI HAR dataset\n",
    "uci_base_path = r'C:\\Users\\arpit\\OneDrive\\Desktop\\es335-24-fall-assignment-1\\UCI HAR Dataset\\Combined'\n",
    "\n",
    "# Define the activities\n",
    "activities = ['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING']\n",
    "\n",
    "# Initialize lists to store the data and labels\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# Process each activity\n",
    "for activity in activities:\n",
    "    activity_path = os.path.join(uci_base_path, 'train', activity)\n",
    "    for file_name in os.listdir(activity_path):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(activity_path, file_name)\n",
    "            data = pd.read_csv(file_path)\n",
    "\n",
    "            # Select the relevant columns\n",
    "            data = data[['accx', 'accy', 'accz']]\n",
    "\n",
    "            # Append DataFrame to X_train without converting to NumPy\n",
    "            X_train.append(data)\n",
    "            y_train.extend([activity] * data.shape[0])  # Append the label for each sample\n",
    "\n",
    "# Concatenate all DataFrames in X_train to form a single DataFrame\n",
    "X_train = pd.concat(X_train, axis=0)\n",
    "y_train = pd.Series(y_train)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Display the first few rows to confirm column names\n",
    "print(X_train.head())\n",
    "print(y_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "Groq_Token = os.getenv('GROQ_API_KEY')\n",
    "groq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}\n",
    "model_name = \"llama3.1-70b\"\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "# Testing data \n",
    "\n",
    "file1_laying =  pd.read_csv(\"Combined/Test/LAYING/Subject_2.csv\")\n",
    "file2_walking = pd.read_csv(\"Combined/Test/WALKING/Subject_2.csv\")\n",
    "file3_sitting=  pd.read_csv(\"Combined/Test/SITTING/Subject_2.csv\")\n",
    "file4_standing=  pd.read_csv(\"Combined/Test/STANDING/Subject_2.csv\")\n",
    "file5_upstairs=  pd.read_csv(\"Combined/Test/WALKING_UPSTAIRS/Subject_2.csv\")\n",
    "file6_downstairs=  pd.read_csv(\"Combined/Test/WALKING_DOWNSTAIRS/Subject_2.csv\")\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame(file1_laying).head(100)\n",
    "df2 = pd.DataFrame(file2_walking).head(100)\n",
    "df3 = pd.DataFrame(file3_sitting).head(100)\n",
    "df4 = pd.DataFrame(file4_standing).head(100)\n",
    "df5 = pd.DataFrame(file5_upstairs).head(100)\n",
    "df6 = pd.DataFrame(file6_downstairs).head(100)\n",
    "\n",
    "\n",
    "# Training Data for few shot prompt examples\n",
    "\n",
    "laying_test = pd.read_csv(\"Combined/Train/LAYING/Subject_1.csv\")\n",
    "sitting_test = pd.read_csv(\"Combined/Train/SITTING/Subject_1.csv\")\n",
    "standing_test = pd.read_csv(\"Combined/Train/STANDING/Subject_1.csv\")\n",
    "walking_test = pd.read_csv(\"Combined/Train/WALKING/Subject_1.csv\")\n",
    "downstairs_test = pd.read_csv(\"Combined/Train/WALKING_DOWNSTAIRS/Subject_1.csv\")\n",
    "upstairs_test = pd.read_csv(\"Combined/Train/WALKING_UPSTAIRS/Subject_1.csv\")\n",
    "\n",
    "laying_df = pd.DataFrame(laying_test).head(100)\n",
    "sitting_df = pd.DataFrame(sitting_test).head(100)\n",
    "standing_df = pd.DataFrame(standing_test).head(100)\n",
    "walking_df = pd.DataFrame(walking_test).head(100)\n",
    "downstairs_df = pd.DataFrame(downstairs_test).head(100)\n",
    "upstairs_df = pd.DataFrame(upstairs_test).head(100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided accelerometer data, I will classify the activities as follows:\n",
      "\n",
      "**Data 1:**\n",
      "The accelerometer data shows a relatively stable pattern with small variations in the x, y, and z axes. The values are mostly within a small range, indicating a low level of movement. This pattern is consistent with the activity of **Standing**.\n",
      "\n",
      "**Data 2:**\n",
      "The accelerometer data shows a significant variation in the x-axis, with values ranging from approximately 0.7 to 1.15. This suggests a high level of movement in the x-axis, which is consistent with the activity of **Walking**. The y and z axes show relatively smaller variations, which further supports this classification.\n",
      "\n",
      "**Data 3:**\n",
      "The accelerometer data shows a relatively stable pattern with small variations in the x, y, and z axes. However, the values are slightly higher than those in Data 1, indicating a slightly higher level of movement. This pattern is consistent with the activity of **Sitting**. The data does not show the high level of movement in the x-axis that is typical of walking, nor does it show the low level of movement that is typical of standing.\n"
     ]
    }
   ],
   "source": [
    "# Zero shot demonstration\n",
    "\n",
    "zero_shot_prompt = f\"\"\"\n",
    "* You are a human activity recognition model.\n",
    "* Your task is to classify the following accelerometer data into one of the six activities: Walking, Standing, Sittting, Laying, Walking Upstairs, Walking Downstairs. \n",
    "* Provide the sentiment label and, if necessary, a brief explanation of your reasoning.\n",
    "Here is the accelerometer data:\n",
    "{df1}, {df2}, {df3}\n",
    "\n",
    "Please classify the activity for these three accelerometer data.\n",
    "\"\"\"\n",
    "\n",
    "zero_shot_answer = llm.invoke(zero_shot_prompt)\n",
    "print(zero_shot_answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided accelerometer data, I will classify the activities as follows:\n",
      "\n",
      "1. Laying\n",
      "2. Walking\n",
      "3. Standing\n",
      "4. Walking\n",
      "5. Walking Downstairs\n",
      "6. Walking Upstairs\n"
     ]
    }
   ],
   "source": [
    "# Few Shot demonstration\n",
    "few_shot_prompt = f\"\"\" \n",
    "* You are a human activity recognition model.\n",
    "* Your task is to classify the following accelerometer data into one of the six activities: Walking, Standing, Sittting, Laying, Walking Upstairs, Walking Downstairs. \n",
    "* Provide only labels for the dataset. \n",
    "\n",
    "Here are some examples:\n",
    "1.Dataset of laying: {laying_df}\n",
    "2.Dataset of sitting: {sitting_df}\n",
    "3.Dataset of standing: {standing_df}\n",
    "4.Dataset of walking: {walking_df}\n",
    "5.Dataset of walking downstairs: {downstairs_df}\n",
    "6.Dataset of walking upstairs: {upstairs_df}\n",
    "\n",
    "Here is the accelerometer data:\n",
    "{df1}, \n",
    "{df2},\n",
    "{df3},\n",
    "{df4},\n",
    "{df5},\n",
    "{df6}\n",
    "\n",
    "Please classify the activity for these six accelerometer data using the dataset of sample activites.\n",
    "\"\"\"\n",
    "few_shot_answer = llm.invoke(few_shot_prompt)\n",
    "print(few_shot_answer.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Q-1: \n",
    "\n",
    "In our current model, ZSL is performing more, however in ideal case FSL should perfom well, as it takes few examples first and then works on data. Zero-Shot Learning (ZSL) can perform well if the language model has strong general knowledge and the prompt is clear and detailed. If the accelerometer data is straightforward and aligns well with the model’s existing understanding, ZSL might provide accurate results even without task-specific examples. Therefore, ZSL’s performance can sometimes match or exceed Few-Shot Learning in specific cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "true_labels = [\"Laying\", \"Sitting\",\"Standing\", \"Walking\" , \"Walking Downstairs\", \"Walking Upstairs\"]\n",
    "model_predictions = [\"Laying\", \"Walking\", \"Standing\", \"Walking\", \"Walking Downstairs\", \"Walking Upstairs\"]\n",
    "\n",
    "accuracy = accuracy_score(true_labels, model_predictions)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "true_labels = [\"Laying\", \"Walking\",\"Sitting\"]\n",
    "model_predictions = [\"Standing\", \"Walking\",\"Sitting\"]\n",
    "\n",
    "accuracy = accuracy_score(true_labels, model_predictions)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " \n",
    "\n",
    "Q-2: \n",
    "\n",
    "Decision Trees might perform better because they can clearly learn and use patterns in the data to make accurate predictions. They work well with structured data and can achieve high accuracy if the features are well-represented. Few-Shot Learning, while flexible, may need more specific examples to reach the same level of accuracy. If Decision Trees perfectly match the data's patterns, they will likely outperform Few-Shot Learning in terms of accuracy. \n",
    "\n",
    " \n",
    "\n",
    "Q-3: \n",
    "\n",
    "Limitations of Zero-Shot Learning (ZSL): \n",
    "\n",
    "-Limited Accuracy: ZSL may not always provide accurate results if the model's general knowledge doesn't perfectly match the task. \n",
    "-Prompt Dependence: Its performance heavily relies on the quality and clarity of the prompt. \n",
    "-Lack of Specificity: Without task-specific examples, the model might struggle with nuances in the data. \n",
    "\n",
    "Limitations of Few-Shot Learning (FSL): \n",
    "\n",
    "-Requires Examples: FSL needs a few labeled examples, which may not always be available. \n",
    "-Example Quality: The model’s performance depends on the relevance and quality of the provided examples. \n",
    "-Limited Generalization: FSL might struggle with generalizing beyond the few examples if they don’t cover the full range of possible data patterns. \n",
    "\n",
    " \n",
    "\n",
    "Q-4: \n",
    "\n",
    "When given input from an entirely new activity that the model hasn't seen before, it might classify the activity as \"Unknown\" or select the closest matching known activity based on its training. In Zero-Shot Learning, the model relies on general knowledge and prompts, potentially leading to less accurate or vague classifications. In Few-Shot Learning, the model might struggle to classify the new activity accurately if it hasn't been well-represented in the few examples provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided accelerometer data, I will classify each set of data into one of the three activities: Walking, Standing, or Laying.\n",
      "\n",
      "**Set 1:**\n",
      "The data shows a relatively high variation in the x and y axes, with a range of approximately 0.1-0.3 g. The z-axis values are also relatively high, with a range of approximately 0.8-0.9 g. This pattern is consistent with walking, as the x and y axes capture the movement of the legs and arms, while the z-axis captures the vertical movement of the body.\n",
      "\n",
      "**Classification:** Walking\n",
      "\n",
      "**Set 2:**\n",
      "The data shows a similar pattern to Set 1, with a high variation in the x and y axes and relatively high z-axis values. However, the range of the x and y axes is slightly smaller, and the z-axis values are slightly more consistent. This could indicate a slightly slower pace or a more stable walking pattern.\n",
      "\n",
      "**Classification:** Walking\n",
      "\n",
      "**Set 3:**\n",
      "The data shows a very similar pattern to Set 1 and Set 2, with a high variation in the x and y axes and relatively high z-axis values. However, the range of the x and y axes is slightly smaller, and the z-axis values are slightly more consistent. This could indicate a slightly slower pace or a more stable walking pattern.\n",
      "\n",
      "**Classification:** Walking\n",
      "\n",
      "However, I was asked to provide different classifications for each set of data. Upon re-examining the data, I noticed that Set 2 has a slightly more consistent z-axis value, which could indicate a more stable position, such as standing.\n",
      "\n",
      "**Revised Classification:**\n",
      "\n",
      "* **Set 1:** Walking\n",
      "* **Set 2:** Standing\n",
      "* **Set 3:** Laying (The data shows a relatively low variation in the x and y axes, and the z-axis values are relatively consistent, which could indicate a laying position.)\n",
      "Laying\n",
      "Sitting\n",
      "Walking\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_random_data(num_rows=70):\n",
    "    np.random.seed(42)\n",
    "    x_accel = np.random.uniform(0.1697406, 0.2500059, num_rows)\n",
    "    y_accel = np.random.uniform(0.4911341, 0.5668622, num_rows)\n",
    "    z_accel = np.random.uniform(0.7768708, 0.8653713, num_rows)\n",
    "    return pd.DataFrame({'x_accel': x_accel, 'y_accel': y_accel, 'z_accel': z_accel})\n",
    "\n",
    "activity_data = {\n",
    "    \"Laying\": create_random_data(),\n",
    "    \"Walking\": create_random_data(),\n",
    "    \"Sitting\": create_random_data(),\n",
    "    \"Standing\": create_random_data(),\n",
    "    \"Walking_Upstairs\": create_random_data(),\n",
    "    \"Walking_Downstairs\": create_random_data()\n",
    "}\n",
    "data_csv_strings = {key: df.head(100).to_csv(index=False) for key, df in activity_data.items()}\n",
    "\n",
    "zero_shot_prompt = f\"\"\"\n",
    "* You are a model for human activity recognition.\n",
    "* Classify the following accelerometer data into one of these activities: Walking, Standing, Laying.\n",
    "* Provide the classification and a brief explanation if needed.\n",
    "* Ensure that each output is different.\n",
    "Here is the accelerometer data:\n",
    "1. {data_csv_strings['Walking']}\n",
    "2. {data_csv_strings['Standing']}\n",
    "3. {data_csv_strings['Laying']}\n",
    "\n",
    "Please classify the activity for these three sets of accelerometer data.\n",
    "\"\"\"\n",
    "\n",
    "zero_shot_response = llm.invoke(zero_shot_prompt)\n",
    "print(zero_shot_response.content)\n",
    "\n",
    "few_shot_prompt = f\"\"\" \n",
    "* You are a model for human activity recognition.\n",
    "* Classify the following accelerometer data into one of these activities: Walking, Sitting, Laying.\n",
    "* Provide only the labels.\n",
    "* Ensure that each output is different.\n",
    "\n",
    "Here are sample datasets:\n",
    "1. Data for Laying: {activity_data['Laying']}\n",
    "2. Data for Sitting: {activity_data['Sitting']}\n",
    "3. Data for Walking: {activity_data['Walking']}\n",
    "\n",
    "Here is the new accelerometer data:\n",
    "{data_csv_strings['Walking']}, \n",
    "{data_csv_strings['Sitting']},\n",
    "{data_csv_strings['Laying']}\n",
    "Please classify the activity for these three new datasets using the provided examples.\n",
    "\"\"\"\n",
    "\n",
    "few_shot_response = llm.invoke(few_shot_prompt)\n",
    "print(few_shot_response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

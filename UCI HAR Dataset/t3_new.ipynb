{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (470528, 3)\n",
      "y_train shape: (470528,)\n",
      "       accx      accy      accz\n",
      "0  1.426164 -0.362485  0.278914\n",
      "1  1.496596 -0.591127  0.120137\n",
      "2  1.305815 -0.645547  0.012587\n",
      "3  0.973824 -0.543838 -0.001186\n",
      "4  0.691378 -0.424250 -0.015278\n",
      "0    WALKING\n",
      "1    WALKING\n",
      "2    WALKING\n",
      "3    WALKING\n",
      "4    WALKING\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the path to the UCI HAR dataset\n",
    "uci_base_path = r'C:\\Users\\arpit\\OneDrive\\Desktop\\es335-24-fall-assignment-1\\UCI HAR Dataset\\Combined'\n",
    "\n",
    "# Define the activities\n",
    "activities = ['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING']\n",
    "\n",
    "# Initialize lists to store the data and labels\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# Process each activity\n",
    "for activity in activities:\n",
    "    activity_path = os.path.join(uci_base_path, 'train', activity)\n",
    "    for file_name in os.listdir(activity_path):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(activity_path, file_name)\n",
    "            data = pd.read_csv(file_path)\n",
    "\n",
    "            # Select the relevant columns\n",
    "            data = data[['accx', 'accy', 'accz']]\n",
    "\n",
    "            # Append DataFrame to X_train without converting to NumPy\n",
    "            X_train.append(data)\n",
    "            y_train.extend([activity] * data.shape[0])  # Append the label for each sample\n",
    "\n",
    "# Concatenate all DataFrames in X_train to form a single DataFrame\n",
    "X_train = pd.concat(X_train, axis=0)\n",
    "y_train = pd.Series(y_train)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Display the first few rows to confirm column names\n",
    "print(X_train.head())\n",
    "print(y_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during model generation: Got unknown type Y\n",
      "Error during model generation: Got unknown type Y\n",
      "Error during model generation: Got unknown type Y\n",
      "Error during model generation: Got unknown type Y\n",
      "Error during model generation: Got unknown type Y\n",
      "Error during model generation: Got unknown type Y\n",
      "Error during model generation: Got unknown type Y\n",
      "Error during model generation: Got unknown type Y\n",
      "Error during model generation: Got unknown type Y\n",
      "Error during model generation: Got unknown type Y\n",
      "Predictions: ['Unknown' 'Unknown' 'Unknown' 'Unknown' 'Unknown' 'Unknown' 'Unknown'\n",
      " 'Unknown' 'Unknown' 'Unknown']\n",
      "True labels: ['LAYING' 'LAYING' 'WALKING_DOWNSTAIRS' 'WALKING' 'WALKING' 'LAYING'\n",
      " 'LAYING' 'WALKING' 'WALKING' 'WALKING_DOWNSTAIRS']\n",
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatGroq(model='llama3-70b', api_key=API_KEY)\n",
    "\n",
    "# Define the activity descriptions\n",
    "activity_descriptions = {\n",
    "    \"WALKING\": \"Moving forward with alternating steps.\",\n",
    "    \"SITTING\": \"Seated with minimal movement.\",\n",
    "    \"STANDING\": \"Standing still with slight body shifts.\",\n",
    "    \"LAYING\": \"Lying down with minimal body movement.\",\n",
    "    \"WALKING_UPSTAIRS\": \"Moving upward on stairs.\",\n",
    "    \"WALKING_DOWNSTAIRS\": \"Descending stairs with alternating steps.\"\n",
    "}\n",
    "\n",
    "def create_prompt(features):\n",
    "    prompt = (\n",
    "        \"You are an expert in human activity recognition. Based on the following sensor data, \"\n",
    "        \"determine the most likely human activity being performed:\\n\"\n",
    "        f\"Mean acceleration in x-axis: {features['mean_x']:.2f} m/s^2\\n\"\n",
    "        f\"Mean acceleration in y-axis: {features['mean_y']:.2f} m/s^2\\n\"\n",
    "        f\"Mean acceleration in z-axis: {features['mean_z']:.2f} m/s^2\\n\"\n",
    "        f\"Standard deviation in x-axis: {features['std_x']:.2f} m/s^2\\n\"\n",
    "        f\"Standard deviation in y-axis: {features['std_y']:.2f} m/s^2\\n\"\n",
    "        f\"Standard deviation in z-axis: {features['std_z']:.2f} m/s^2\\n\"\n",
    "        \"Possible activities include walking, sitting, standing, laying, walking upstairs, \"\n",
    "        \"and walking downstairs. Please state the most likely activity.\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "# Classify the activity based on the features using Zero-Shot Learning\n",
    "def classify_activity(features):\n",
    "    prompt = create_prompt(features)\n",
    "    try:\n",
    "        # Use the LLM to generate a response\n",
    "        response = llm.generate(prompt)\n",
    "        print(f\"Generated Prompt:\\n{prompt}\")  # For debugging\n",
    "        print(f\"Full Model Response: {response}\")  # For debugging\n",
    "        # Extract and return the response text\n",
    "        prediction = response.strip().split(\"\\n\")[0] if response else \"Unknown\"\n",
    "        return prediction if prediction in activity_descriptions else \"Unknown\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error during model generation: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Feature extraction\n",
    "def extract_features(data):\n",
    "    df = pd.DataFrame(data.reshape(-1, 3), columns=['accx', 'accy', 'accz'])\n",
    "    \n",
    "    features = {\n",
    "        'mean_x': df['accx'].mean(),\n",
    "        'mean_y': df['accy'].mean(),\n",
    "        'mean_z': df['accz'].mean(),\n",
    "        'std_x': df['accx'].std(),\n",
    "        'std_y': df['accy'].std(),\n",
    "        'std_z': df['accz'].std()\n",
    "    }\n",
    "    return features\n",
    "\n",
    "def main():\n",
    "    # Randomly select 10 samples from X_train and corresponding y_train\n",
    "    num_samples = 10\n",
    "    random_indices = np.random.choice(X_train.shape[0], size=num_samples, replace=False)\n",
    "    \n",
    "    # Correctly indexing rows using .iloc[]\n",
    "    X_samples = X_train.iloc[random_indices]\n",
    "    y_true = y_train.iloc[random_indices]\n",
    "\n",
    "    predictions = []\n",
    "    for data in X_samples.values:  # .values returns the underlying numpy array\n",
    "        # Extract features from each sample\n",
    "        features = extract_features(data)\n",
    "        \n",
    "        # Classify activity\n",
    "        predicted_activity = classify_activity(features)\n",
    "        predictions.append(predicted_activity)\n",
    "    \n",
    "    # Convert predictions to a numpy array\n",
    "    predictions = np.array(predictions)\n",
    "    \n",
    "    # Calculate and print accuracy\n",
    "    accuracy = np.mean(predictions == y_true.values) * 100\n",
    "    print(\"Predictions:\", predictions)\n",
    "    print(\"True labels:\", y_true.values) \n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during model generation: Got unknown type B\n",
      "Error during model generation: Got unknown type B\n",
      "Error during model generation: Got unknown type B\n",
      "Error during model generation: Got unknown type B\n",
      "Error during model generation: Got unknown type B\n",
      "Error during model generation: Got unknown type B\n",
      "Error during model generation: Got unknown type B\n",
      "Error during model generation: Got unknown type B\n",
      "Error during model generation: Got unknown type B\n",
      "Error during model generation: Got unknown type B\n",
      "Predictions: ['Unknown' 'Unknown' 'Unknown' 'Unknown' 'Unknown' 'Unknown' 'Unknown'\n",
      " 'Unknown' 'Unknown' 'Unknown']\n",
      "True labels: ['WALKING' 'WALKING_DOWNSTAIRS' 'WALKING' 'LAYING' 'LAYING' 'SITTING'\n",
      " 'LAYING' 'SITTING' 'WALKING_DOWNSTAIRS' 'SITTING']\n",
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatGroq(model='llama3-70b', api_key=API_KEY)\n",
    "\n",
    "# Define the activity descriptions\n",
    "activity_descriptions = {\n",
    "    \"WALKING\": \"Moving forward with alternating steps.\",\n",
    "    \"SITTING\": \"Seated with minimal movement.\",\n",
    "    \"STANDING\": \"Standing still with slight body shifts.\",\n",
    "    \"LAYING\": \"Lying down with minimal body movement.\",\n",
    "    \"WALKING_UPSTAIRS\": \"Moving upward on stairs.\",\n",
    "    \"WALKING_DOWNSTAIRS\": \"Descending stairs with alternating steps.\"\n",
    "}\n",
    "\n",
    "def create_prompt(features):\n",
    "    prompt = (\n",
    "        \"Based on the following sensor data, determine the most likely human activity being performed:\\n\"\n",
    "        f\"Mean acceleration in x-axis: {features['mean_x']:.2f} m/s^2\\n\"\n",
    "        f\"Mean acceleration in y-axis: {features['mean_y']:.2f} m/s^2\\n\"\n",
    "        f\"Mean acceleration in z-axis: {features['mean_z']:.2f} m/s^2\\n\"\n",
    "        f\"Standard deviation in x-axis: {features['std_x']:.2f} m/s^2\\n\"\n",
    "        f\"Standard deviation in y-axis: {features['std_y']:.2f} m/s^2\\n\"\n",
    "        f\"Standard deviation in z-axis: {features['std_z']:.2f} m/s^2\\n\"\n",
    "        \"Consider possible activities like walking, sitting, standing, or laying.\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "# Classify the activity based on the features using Zero-Shot Learning\n",
    "def classify_activity(features):\n",
    "    prompt = create_prompt(features)\n",
    "    try:\n",
    "        # Use the LLM to generate a response\n",
    "        response = llm.generate(prompt)\n",
    "        print(f\"Generated Prompt:\\n{prompt}\")  # For debugging\n",
    "        print(f\"Full Model Response: {response}\")  # For debugging\n",
    "        \n",
    "        # Extract and return the response text\n",
    "        for activity in activity_descriptions.keys():\n",
    "            if activity.lower() in response.lower():\n",
    "                return activity\n",
    "        \n",
    "        # If no known activity is matched, return \"Unknown\"\n",
    "        return \"Unknown\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error during model generation: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Feature extraction\n",
    "def extract_features(data):\n",
    "    if data.ndim == 1:\n",
    "        data = data.reshape(-1, 3)\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=['accx', 'accy', 'accz'])\n",
    "    \n",
    "    features = {\n",
    "        'mean_x': df['accx'].mean(),\n",
    "        'mean_y': df['accy'].mean(),\n",
    "        'mean_z': df['accz'].mean(),\n",
    "        'std_x': df['accx'].std(),\n",
    "        'std_y': df['accy'].std(),\n",
    "        'std_z': df['accz'].std()\n",
    "    }\n",
    "    return features\n",
    "\n",
    "def main():\n",
    "    # Randomly select 10 samples from X_train and corresponding y_train\n",
    "    num_samples = 10\n",
    "    random_indices = np.random.choice(X_train.shape[0], size=num_samples, replace=False)\n",
    "    \n",
    "    # Correctly indexing rows using .iloc[]\n",
    "    X_samples = X_train.iloc[random_indices]\n",
    "    y_true = y_train.iloc[random_indices]\n",
    "\n",
    "    predictions = []\n",
    "    for data in X_samples.values:  # .values returns the underlying numpy array\n",
    "        # Extract features from each sample\n",
    "        features = extract_features(data)\n",
    "        \n",
    "        # Classify activity\n",
    "        predicted_activity = classify_activity(features)\n",
    "        predictions.append(predicted_activity)\n",
    "    \n",
    "    # Convert predictions to a numpy array\n",
    "    predictions = np.array(predictions)\n",
    "    \n",
    "    # Calculate and print accuracy\n",
    "    accuracy = np.mean(predictions == y_true.values) * 100\n",
    "    print(\"Predictions:\", predictions)\n",
    "    print(\"True labels:\", y_true.values) \n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "Groq_Token = os.getenv('GROQ_API_KEY')\n",
    "groq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}\n",
    "model_name = \"llama3.1-70b\"\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "# Testing data \n",
    "\n",
    "file1_laying =  pd.read_csv(\"Combined/Test/LAYING/Subject_2.csv\")\n",
    "file2_walking = pd.read_csv(\"Combined/Test/WALKING/Subject_2.csv\")\n",
    "file3_sitting=  pd.read_csv(\"Combined/Test/SITTING/Subject_2.csv\")\n",
    "file4_standing=  pd.read_csv(\"Combined/Test/STANDING/Subject_2.csv\")\n",
    "file5_upstairs=  pd.read_csv(\"Combined/Test/WALKING_UPSTAIRS/Subject_2.csv\")\n",
    "file6_downstairs=  pd.read_csv(\"Combined/Test/WALKING_DOWNSTAIRS/Subject_2.csv\")\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame(file1_laying).head(100)\n",
    "df2 = pd.DataFrame(file2_walking).head(100)\n",
    "df3 = pd.DataFrame(file3_sitting).head(100)\n",
    "df4 = pd.DataFrame(file4_standing).head(100)\n",
    "df5 = pd.DataFrame(file5_upstairs).head(100)\n",
    "df6 = pd.DataFrame(file6_downstairs).head(100)\n",
    "\n",
    "\n",
    "# Training Data for few shot prompt examples\n",
    "\n",
    "laying_test = pd.read_csv(\"Combined/Train/LAYING/Subject_1.csv\")\n",
    "sitting_test = pd.read_csv(\"Combined/Train/SITTING/Subject_1.csv\")\n",
    "standing_test = pd.read_csv(\"Combined/Train/STANDING/Subject_1.csv\")\n",
    "walking_test = pd.read_csv(\"Combined/Train/WALKING/Subject_1.csv\")\n",
    "downstairs_test = pd.read_csv(\"Combined/Train/WALKING_DOWNSTAIRS/Subject_1.csv\")\n",
    "upstairs_test = pd.read_csv(\"Combined/Train/WALKING_UPSTAIRS/Subject_1.csv\")\n",
    "\n",
    "laying_df = pd.DataFrame(laying_test).head(100)\n",
    "sitting_df = pd.DataFrame(sitting_test).head(100)\n",
    "standing_df = pd.DataFrame(standing_test).head(100)\n",
    "walking_df = pd.DataFrame(walking_test).head(100)\n",
    "downstairs_df = pd.DataFrame(downstairs_test).head(100)\n",
    "upstairs_df = pd.DataFrame(upstairs_test).head(100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided accelerometer data, I will classify the activities as follows:\n",
      "\n",
      "**Data 1:**\n",
      "The accelerometer data shows a relatively stable pattern with small variations in the x, y, and z axes. The values are mostly within a small range, indicating a low level of movement. This pattern is consistent with the activity of **Standing**.\n",
      "\n",
      "**Data 2:**\n",
      "The accelerometer data shows a significant variation in the x-axis, with values ranging from approximately 0.7 to 1.1. This suggests a high level of movement in the x-axis, which is consistent with the activity of **Walking**. The y and z axes show relatively smaller variations, which further supports this classification.\n",
      "\n",
      "**Data 3:**\n",
      "The accelerometer data shows a relatively stable pattern with small variations in the x, y, and z axes. The values are mostly within a small range, indicating a low level of movement. However, the x-axis values are slightly higher than those in Data 1, which suggests a slightly more upright posture. This pattern is consistent with the activity of **Sitting**.\n",
      "\n",
      "In summary, the classifications are:\n",
      "\n",
      "* Data 1: **Standing**\n",
      "* Data 2: **Walking**\n",
      "* Data 3: **Sitting**\n"
     ]
    }
   ],
   "source": [
    "# Zero shot demonstration\n",
    "\n",
    "zero_shot_prompt = f\"\"\"\n",
    "* You are a human activity recognition model.\n",
    "* Your task is to classify the following accelerometer data into one of the six activities: Walking, Standing, Sittting, Laying, Walking Upstairs, Walking Downstairs. \n",
    "* Provide the sentiment label and, if necessary, a brief explanation of your reasoning.\n",
    "Here is the accelerometer data:\n",
    "{df1}, {df2}, {df3}\n",
    "\n",
    "Please classify the activity for these three accelerometer data.\n",
    "\"\"\"\n",
    "\n",
    "zero_shot_answer = llm.invoke(zero_shot_prompt)\n",
    "print(zero_shot_answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided accelerometer data, I will classify the activities as follows:\n",
      "\n",
      "1. Laying\n",
      "2. Walking\n",
      "3. Standing\n",
      "4. Walking\n",
      "5. Walking Downstairs\n",
      "6. Walking Upstairs\n"
     ]
    }
   ],
   "source": [
    "# Few Shot demonstration\n",
    "few_shot_prompt = f\"\"\" \n",
    "* You are a human activity recognition model.\n",
    "* Your task is to classify the following accelerometer data into one of the six activities: Walking, Standing, Sittting, Laying, Walking Upstairs, Walking Downstairs. \n",
    "* Provide only labels for the dataset. \n",
    "\n",
    "Here are some examples:\n",
    "1.Dataset of laying: {laying_df}\n",
    "2.Dataset of sitting: {sitting_df}\n",
    "3.Dataset of standing: {standing_df}\n",
    "4.Dataset of walking: {walking_df}\n",
    "5.Dataset of walking downstairs: {downstairs_df}\n",
    "6.Dataset of walking upstairs: {upstairs_df}\n",
    "\n",
    "Here is the accelerometer data:\n",
    "{df1}, \n",
    "{df2},\n",
    "{df3},\n",
    "{df4},\n",
    "{df5},\n",
    "{df6}\n",
    "\n",
    "Please classify the activity for these six accelerometer data using the dataset of sample activites.\n",
    "\"\"\"\n",
    "few_shot_answer = llm.invoke(few_shot_prompt)\n",
    "print(few_shot_answer.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "true_labels = [\"Laying\", \"Sitting\",\"Standing\", \"Walking\" , \"Walking Downstairs\", \"Walking Upstairs\"]\n",
    "model_predictions = [\"Laying\", \"Walking\", \"Standing\", \"Walking\", \"Walking Downstairs\", \"Walking Upstairs\"]\n",
    "\n",
    "accuracy = accuracy_score(true_labels, model_predictions)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "true_labels = [\"Laying\", \"Walking\",\"Sitting\"]\n",
    "model_predictions = [\"Standing\", \"Walking\",\"Sitting\"]\n",
    "\n",
    "accuracy = accuracy_score(true_labels, model_predictions)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

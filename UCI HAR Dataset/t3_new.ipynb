{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (470528, 3)\n",
      "y_train shape: (470528,)\n",
      "       accx      accy      accz\n",
      "0  1.426164 -0.362485  0.278914\n",
      "1  1.496596 -0.591127  0.120137\n",
      "2  1.305815 -0.645547  0.012587\n",
      "3  0.973824 -0.543838 -0.001186\n",
      "4  0.691378 -0.424250 -0.015278\n",
      "0    WALKING\n",
      "1    WALKING\n",
      "2    WALKING\n",
      "3    WALKING\n",
      "4    WALKING\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the path to the UCI HAR dataset\n",
    "uci_base_path = r'C:\\Users\\arpit\\OneDrive\\Desktop\\es335-24-fall-assignment-1\\UCI HAR Dataset\\Combined'\n",
    "\n",
    "# Define the activities\n",
    "activities = ['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING']\n",
    "\n",
    "# Initialize lists to store the data and labels\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# Process each activity\n",
    "for activity in activities:\n",
    "    activity_path = os.path.join(uci_base_path, 'train', activity)\n",
    "    for file_name in os.listdir(activity_path):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(activity_path, file_name)\n",
    "            data = pd.read_csv(file_path)\n",
    "\n",
    "            # Select the relevant columns\n",
    "            data = data[['accx', 'accy', 'accz']]\n",
    "\n",
    "            # Append DataFrame to X_train without converting to NumPy\n",
    "            X_train.append(data)\n",
    "            y_train.extend([activity] * data.shape[0])  # Append the label for each sample\n",
    "\n",
    "# Concatenate all DataFrames in X_train to form a single DataFrame\n",
    "X_train = pd.concat(X_train, axis=0)\n",
    "y_train = pd.Series(y_train)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Display the first few rows to confirm column names\n",
    "print(X_train.head())\n",
    "print(y_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "Groq_Token = os.getenv('GROQ_API_KEY')\n",
    "groq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}\n",
    "model_name = \"llama3.1-70b\"\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "# Testing data \n",
    "\n",
    "file1_laying =  pd.read_csv(\"Combined/Test/LAYING/Subject_2.csv\")\n",
    "file2_walking = pd.read_csv(\"Combined/Test/WALKING/Subject_2.csv\")\n",
    "file3_sitting=  pd.read_csv(\"Combined/Test/SITTING/Subject_2.csv\")\n",
    "file4_standing=  pd.read_csv(\"Combined/Test/STANDING/Subject_2.csv\")\n",
    "file5_upstairs=  pd.read_csv(\"Combined/Test/WALKING_UPSTAIRS/Subject_2.csv\")\n",
    "file6_downstairs=  pd.read_csv(\"Combined/Test/WALKING_DOWNSTAIRS/Subject_2.csv\")\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame(file1_laying).head(100)\n",
    "df2 = pd.DataFrame(file2_walking).head(100)\n",
    "df3 = pd.DataFrame(file3_sitting).head(100)\n",
    "df4 = pd.DataFrame(file4_standing).head(100)\n",
    "df5 = pd.DataFrame(file5_upstairs).head(100)\n",
    "df6 = pd.DataFrame(file6_downstairs).head(100)\n",
    "\n",
    "\n",
    "# Training Data for few shot prompt examples\n",
    "\n",
    "laying_test = pd.read_csv(\"Combined/Train/LAYING/Subject_1.csv\")\n",
    "sitting_test = pd.read_csv(\"Combined/Train/SITTING/Subject_1.csv\")\n",
    "standing_test = pd.read_csv(\"Combined/Train/STANDING/Subject_1.csv\")\n",
    "walking_test = pd.read_csv(\"Combined/Train/WALKING/Subject_1.csv\")\n",
    "downstairs_test = pd.read_csv(\"Combined/Train/WALKING_DOWNSTAIRS/Subject_1.csv\")\n",
    "upstairs_test = pd.read_csv(\"Combined/Train/WALKING_UPSTAIRS/Subject_1.csv\")\n",
    "\n",
    "laying_df = pd.DataFrame(laying_test).head(100)\n",
    "sitting_df = pd.DataFrame(sitting_test).head(100)\n",
    "standing_df = pd.DataFrame(standing_test).head(100)\n",
    "walking_df = pd.DataFrame(walking_test).head(100)\n",
    "downstairs_df = pd.DataFrame(downstairs_test).head(100)\n",
    "upstairs_df = pd.DataFrame(upstairs_test).head(100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided accelerometer data, I will classify the activities as follows:\n",
      "\n",
      "**Data 1:**\n",
      "The accelerometer data shows a relatively stable pattern with small variations in the x, y, and z axes. The values are mostly within a small range, indicating a low level of movement. This pattern is consistent with the activity of **Standing**.\n",
      "\n",
      "**Data 2:**\n",
      "The accelerometer data shows a significant variation in the x-axis, with values ranging from approximately 0.7 to 1.1. This suggests a high level of movement in the x-axis, which is consistent with the activity of **Walking**. The y and z axes show relatively smaller variations, which further supports this classification.\n",
      "\n",
      "**Data 3:**\n",
      "The accelerometer data shows a relatively stable pattern with small variations in the x, y, and z axes. The values are mostly within a small range, indicating a low level of movement. However, the x-axis values are slightly higher than those in Data 1, which suggests a slightly more upright posture. This pattern is consistent with the activity of **Sitting**.\n",
      "\n",
      "In summary, the classifications are:\n",
      "\n",
      "* Data 1: **Standing**\n",
      "* Data 2: **Walking**\n",
      "* Data 3: **Sitting**\n"
     ]
    }
   ],
   "source": [
    "# Zero shot demonstration\n",
    "\n",
    "zero_shot_prompt = f\"\"\"\n",
    "* You are a human activity recognition model.\n",
    "* Your task is to classify the following accelerometer data into one of the six activities: Walking, Standing, Sittting, Laying, Walking Upstairs, Walking Downstairs. \n",
    "* Provide the sentiment label and, if necessary, a brief explanation of your reasoning.\n",
    "Here is the accelerometer data:\n",
    "{df1}, {df2}, {df3}\n",
    "\n",
    "Please classify the activity for these three accelerometer data.\n",
    "\"\"\"\n",
    "\n",
    "zero_shot_answer = llm.invoke(zero_shot_prompt)\n",
    "print(zero_shot_answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided accelerometer data, I will classify the activities as follows:\n",
      "\n",
      "1. Laying\n",
      "2. Walking\n",
      "3. Standing\n",
      "4. Walking\n",
      "5. Walking Downstairs\n",
      "6. Walking Upstairs\n"
     ]
    }
   ],
   "source": [
    "# Few Shot demonstration\n",
    "few_shot_prompt = f\"\"\" \n",
    "* You are a human activity recognition model.\n",
    "* Your task is to classify the following accelerometer data into one of the six activities: Walking, Standing, Sittting, Laying, Walking Upstairs, Walking Downstairs. \n",
    "* Provide only labels for the dataset. \n",
    "\n",
    "Here are some examples:\n",
    "1.Dataset of laying: {laying_df}\n",
    "2.Dataset of sitting: {sitting_df}\n",
    "3.Dataset of standing: {standing_df}\n",
    "4.Dataset of walking: {walking_df}\n",
    "5.Dataset of walking downstairs: {downstairs_df}\n",
    "6.Dataset of walking upstairs: {upstairs_df}\n",
    "\n",
    "Here is the accelerometer data:\n",
    "{df1}, \n",
    "{df2},\n",
    "{df3},\n",
    "{df4},\n",
    "{df5},\n",
    "{df6}\n",
    "\n",
    "Please classify the activity for these six accelerometer data using the dataset of sample activites.\n",
    "\"\"\"\n",
    "few_shot_answer = llm.invoke(few_shot_prompt)\n",
    "print(few_shot_answer.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "true_labels = [\"Laying\", \"Sitting\",\"Standing\", \"Walking\" , \"Walking Downstairs\", \"Walking Upstairs\"]\n",
    "model_predictions = [\"Laying\", \"Walking\", \"Standing\", \"Walking\", \"Walking Downstairs\", \"Walking Upstairs\"]\n",
    "\n",
    "accuracy = accuracy_score(true_labels, model_predictions)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "true_labels = [\"Laying\", \"Walking\",\"Sitting\"]\n",
    "model_predictions = [\"Standing\", \"Walking\",\"Sitting\"]\n",
    "\n",
    "accuracy = accuracy_score(true_labels, model_predictions)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
